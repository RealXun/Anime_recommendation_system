{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animedf['genre'] = animedf['genre'].str.replace(' ', '')\n",
    "animedf = animedf[animedf['genre'].notna()]\n",
    "animedf['genre'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_list = []\n",
    "for item in animedf['genre']:\n",
    "    item = item.strip().split(',')\n",
    "    categ_list.extend(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'Action': 0, 'SuperPower': 0, 'Adventure': 0, 'Seinen': 0, 'Music': 0, 'Historical': 0, 'Game': 0, 'Josei': 0, 'SliceofLife': 0, 'Demons': 0,\n",
    "        'Yaoi': 0, 'Romance': 0, 'Psychological': 0, 'Comedy': 0, 'Mecha': 0, 'Magic': 0, 'Horror': 0, 'ShounenAi': 0, 'Hentai': 0, 'Vampire': 0,\n",
    "        'Ecchi': 0, 'MartialArts': 0, 'Dementia': 0, 'Sports': 0, 'Harem': 0, 'Mystery': 0, 'Shounen': 0, 'Samurai': 0, 'Fantasy': 0, 'Sci-Fi': 0,\n",
    "        'Yuri': 0, 'Thriller': 0, 'Space': 0, 'School': 0, 'Shoujo': 0, 'Cars': 0, 'Kids': 0, 'ShoujoAi': 0, 'Supernatural': 0, 'Parody': 0,\n",
    "        'Police': 0, 'Military': 0, 'Drama': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for celda in animedf['genre']:\n",
    "    for word in celda.split():\n",
    "        for gender in dict.keys():\n",
    "            if word.replace(',', '') == gender:\n",
    "                dict[gender] += 1\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_2 = []\n",
    "\n",
    "for index, celda in enumerate(animedf['genre']):\n",
    "    print(index)\n",
    "    nueva_celda = 0\n",
    "    for word in celda.split():\n",
    "        nueva_celda += dict[word.replace(',', '')]\n",
    "    lista_2.append(nueva_celda)\n",
    "    \n",
    "print(lista_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1):\n",
    " \n",
    "    # insert the list to the set\n",
    "    list_set = set(list1)\n",
    "    # convert the set to the list\n",
    "    unique_list = (list(list_set))\n",
    "    for x in unique_list:\n",
    "        print (x)\n",
    "unique(categ_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1: uses pandas\n",
    "merged_df['genre'] = merged_df['genre'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the missing values with the RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N. rows with genre not null: 7813617\n",
      "N. rows with genre null: 110\n"
     ]
    }
   ],
   "source": [
    "df_with_genre = merged_df[merged_df['genre'].notna()]\n",
    "print(\"N. rows with genre not null:\", df_with_genre.shape[0])\n",
    "\n",
    "df_no_genre = merged_df[merged_df['genre'].isna()]\n",
    "print(\"N. rows with genre null:\", df_no_genre.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[14], line 14\u001b[0m\n",
      "\u001b[0;32m      9\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;32m     11\u001b[0m forest \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m45\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \n",
      "\u001b[0;32m     12\u001b[0m                                 max_features\u001b[39m=\u001b[39m\u001b[39m0.6\u001b[39m, min_samples_leaf\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m---> 14\u001b[0m forest\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "\u001b[0;32m     16\u001b[0m y_pred_train \u001b[39m=\u001b[39m forest\u001b[39m.\u001b[39mpredict(X_train)\n",
      "\u001b[0;32m     17\u001b[0m y_pred \u001b[39m=\u001b[39m forest\u001b[39m.\u001b[39mpredict(X_test)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\christiandda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:346\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n",
      "\u001b[0;32m    344\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n",
      "\u001b[0;32m    345\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m--> 346\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n",
      "\u001b[0;32m    347\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n",
      "\u001b[0;32m    348\u001b[0m )\n",
      "\u001b[0;32m    349\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;32m    350\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\christiandda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:554\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n",
      "\u001b[0;32m    552\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n",
      "\u001b[0;32m    553\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m--> 554\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n",
      "\u001b[0;32m    555\u001b[0m     out \u001b[39m=\u001b[39m X, y\n",
      "\u001b[0;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\christiandda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1104\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n",
      "\u001b[0;32m   1099\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n",
      "\u001b[0;32m   1100\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n",
      "\u001b[0;32m   1101\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m   1102\u001b[0m     )\n",
      "\u001b[1;32m-> 1104\u001b[0m X \u001b[39m=\u001b[39m check_array(\n",
      "\u001b[0;32m   1105\u001b[0m     X,\n",
      "\u001b[0;32m   1106\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n",
      "\u001b[0;32m   1107\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n",
      "\u001b[0;32m   1108\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n",
      "\u001b[0;32m   1109\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n",
      "\u001b[0;32m   1110\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n",
      "\u001b[0;32m   1111\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n",
      "\u001b[0;32m   1112\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n",
      "\u001b[0;32m   1113\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n",
      "\u001b[0;32m   1114\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n",
      "\u001b[0;32m   1115\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n",
      "\u001b[0;32m   1116\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n",
      "\u001b[0;32m   1117\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n",
      "\u001b[0;32m   1118\u001b[0m )\n",
      "\u001b[0;32m   1120\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n",
      "\u001b[0;32m   1122\u001b[0m check_consistent_length(X, y)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\christiandda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:877\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n",
      "\u001b[0;32m    875\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;32m    876\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m--> 877\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n",
      "\u001b[0;32m    878\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n",
      "\u001b[0;32m    879\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n",
      "\u001b[0;32m    880\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n",
      "\u001b[0;32m    881\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\christiandda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n",
      "\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n",
      "\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n",
      "\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n",
      "\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n",
      "\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Unknown'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_with_genre.drop([\"genre\",\"anime_title\",\"type\"], axis=1).values\n",
    "y = df_with_genre[\"genre\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=45, max_depth=25, random_state=False, \n",
    "                                max_features=0.6, min_samples_leaf=3, n_jobs=-1)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = forest.predict(X_train)\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "y_pred_proba = forest.predict_proba(X_test)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"ACCURACY: TRAIN=%.4f TEST=%.4f\" % (accuracy_train,accuracy_test))\n",
    "print(\"LOG LOSS: \"+str(log_loss(y_test, y_pred_proba)))\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "indices = list(np.argsort(importances))[::-1]\n",
    "\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(range(len(indices)), importances[indices], color=\"g\", align=\"center\")\n",
    "plt.yticks(range(len(indices)), df_with_genre.iloc[:, 1:].columns[indices])\n",
    "\n",
    "plt.gca().invert_yaxis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letâ€™s fill the 2nd dataframe with the values of the prediction\n",
    "df_no_genre = df_no_genre.drop('genre', axis=1)\n",
    "prediction = forest.predict(df_no_genre)\n",
    "\n",
    "df_no_genre.insert(0, 'genre', prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cff4678dccc161ee1c6f25be5e3677ea130d7193750bbc4b79c480bbe89cc2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

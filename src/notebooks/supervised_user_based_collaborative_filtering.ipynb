{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised user based collaborative filtering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chrisitan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os # allows access to OS-dependent functionalities\n",
    "import re #  regular expression matching operations similar to those found in Perl\n",
    "import sys # to manipulate different parts of the Python runtime environment\n",
    "import warnings # is used to display the message Warning\n",
    "import pickle # serializing and deserializing a Python object structure.\n",
    "\n",
    "# Third party libraries\n",
    "from fastparquet import write # parquet format, aiming integrate into python-based big data work-flows\n",
    "from fuzzywuzzy import fuzz # used for string matching\n",
    "\n",
    "import numpy as np # functions for working in domain of linear algebra, fourier transform, matrices and arrays\n",
    "import pandas as pd # data analysis and manipulation tool\n",
    "import joblib # set of tools to provide lightweight pipelining in Python\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt # collection of functions that make matplotlib work like MATLAB.\n",
    "\n",
    "# Surprise libraries\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.model_selection import GridSearchCV, train_test_split, cross_validate\n",
    "from surprise import SVD, SVDpp, SlopeOne, NMF, NormalPredictor, KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore, BaselineOnly, CoClustering\n",
    "\n",
    "# pip install git+https://github.com/NicolasHug/surprise.git\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Add the path of the utils directory to sys.path\n",
    "utils_path = os.path.abspath(os.path.join(cwd, '..', 'utils'))\n",
    "sys.path.append(utils_path)\n",
    "\n",
    "# Utils libraries\n",
    "from cleaning import *\n",
    "from recommend import *\n",
    "from testing import *\n",
    "from training import *\n",
    "\n",
    "#Preparing folder variables\n",
    "\n",
    "main_folder = os.path.abspath(os.path.join(os.pardir))\n",
    "data_folder = (main_folder + \"/\" +\"data\")\n",
    "saved_models_folder = (data_folder + \"/\" + \"saved_models\")\n",
    "raw_data = (data_folder + \"/\" + \"_raw\")\n",
    "processed_data = (data_folder + \"/\" + \"processed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file called \"anime.csv\" from a directory called raw_data and returns the contents as a Pandas DataFrame\n",
    "anime = pd.read_csv(raw_data + \"/\" + \"anime.csv\") \n",
    "\n",
    "# CSV file called \"rating.csv.zip\" from a directory called raw_data and returns the contents as a Pandas DataFrame\n",
    "rating = pd.read_csv(raw_data + \"/\" + \"rating.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>226</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  anime_id  rating\n",
       "0        1        20      -1\n",
       "1        1        24      -1\n",
       "2        1        79      -1\n",
       "3        1       226      -1\n",
       "4        1       241      -1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7813737, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.813737e+06</td>\n",
       "      <td>7.813737e+06</td>\n",
       "      <td>7.813737e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.672796e+04</td>\n",
       "      <td>8.909072e+03</td>\n",
       "      <td>6.144030e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.099795e+04</td>\n",
       "      <td>8.883950e+03</td>\n",
       "      <td>3.727800e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.897400e+04</td>\n",
       "      <td>1.240000e+03</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.679100e+04</td>\n",
       "      <td>6.213000e+03</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.475700e+04</td>\n",
       "      <td>1.409300e+04</td>\n",
       "      <td>9.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.351600e+04</td>\n",
       "      <td>3.451900e+04</td>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id      anime_id        rating\n",
       "count  7.813737e+06  7.813737e+06  7.813737e+06\n",
       "mean   3.672796e+04  8.909072e+03  6.144030e+00\n",
       "std    2.099795e+04  8.883950e+03  3.727800e+00\n",
       "min    1.000000e+00  1.000000e+00 -1.000000e+00\n",
       "25%    1.897400e+04  1.240000e+03  6.000000e+00\n",
       "50%    3.679100e+04  6.213000e+03  7.000000e+00\n",
       "75%    5.475700e+04  1.409300e+04  9.000000e+00\n",
       "max    7.351600e+04  3.451900e+04  1.000000e+01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(supervised_rating_cleaning.__doc__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps of supervised_rating_cleaning:\n",
    "- selects only those rows from the 'rating' DataFrame where the value of the 'rating' column is greater than 0. The resulting DataFrame is assigned to the variable 'ratingdf'.\n",
    "- resets the index of the 'ratingdf' DataFrame. This means that the current index is replaced with a sequential index starting from 0, and a new column called 'index' is added to the DataFrame to store the old index values.\n",
    "- drops the 'index' column from the 'ratingdf' DataFrame. The 'axis=1' argument specifies that the column should be dropped, and 'inplace=True' means that the changes should be made to the DataFrame in place (i.e., the DataFrame is modified directly rather than creating a copy).\n",
    "- returns the modified 'ratingdf' DataFrame as the output of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data\n",
    "ratingdf = supervised_rating_cleaning(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6337241, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingdf.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data for baseline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In here we are goin to prepare de data to be used in the model baseline.\n",
    "\n",
    "To do a baseline we will use a smaller dataset and then use the whole dataset in the selected mode. Because using a smaller dataset for prototyping and testing can be a good way to quickly iterate and experiment with different algorithms and hyperparameters before scaling up to the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_different_models():\n",
    "    '''\n",
    "    The code reads two CSV files (anime.csv and rating.csv.zip) and loads them into dataframes. \n",
    "    Then it creates a subset of the rating dataframe containing only rows where the rating is \n",
    "    greater than 0 and removes the index column. Next, it samples a subset of the data with \n",
    "    a specified size, grouped by the rating column.\n",
    "    '''\n",
    "    # Load 'anime.csv' file into a pandas DataFrame object called 'anime'\n",
    "    anime = pd.read_csv(raw_data + \"/\" + \"anime.csv\")\n",
    "\n",
    "    # Load 'rating.csv.zip' file into a pandas DataFrame object called 'rating'\n",
    "    rating = pd.read_csv(raw_data + \"/\" + \"rating.csv.zip\")\n",
    "\n",
    "    # Create a new DataFrame 'anime_mapping' that is a copy of the 'anime' DataFrame and remove the 'episodes', 'members', and 'rating' columns\n",
    "    anime_mapping = anime.copy()\n",
    "    anime_mapping.drop(['episodes','members','rating'],axis=1, inplace=True)\n",
    "\n",
    "    # Filter out all ratings less than or equal to 0 and reset the index of the DataFrame\n",
    "    ratingdf = rating[rating.rating>0]\n",
    "    ratingdf = ratingdf.reset_index()\n",
    "\n",
    "    # Drop the 'index' column and update the DataFrame in-place\n",
    "    ratingdf.drop('index', axis=1, inplace=True)\n",
    "\n",
    "    # Get the shape of the DataFrame 'ratingdf'\n",
    "    ratingdf.shape\n",
    "\n",
    "    # Set the size to 100,000 and sample from the 'ratingdf' DataFrame based on the proportion of ratings for each score\n",
    "    size = 100000\n",
    "\n",
    "    # This will make sure that the sampled data has roughly the same proportion of ratings for each score as the original data\n",
    "    ratingdf_sample = ratingdf.groupby(\"rating\", group_keys=False).apply(lambda x: x.sample(int(np.rint(size*len(x)/len(ratingdf))))).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Create a new 'Reader' object with the rating scale set to a range between 1 and 10\n",
    "    reader = Reader(rating_scale=(1,10))\n",
    "\n",
    "    # Load the sampled data into a 'Dataset' object using the 'load_from_df' method and the 'reader' object\n",
    "    data = Dataset.load_from_df(ratingdf_sample[['user_id', 'anime_id', 'rating']], reader)\n",
    "\n",
    "    # Saving the table to pickle\n",
    "    joblib.dump(data,processed_data + \"/\" + \"data_reader_for_different_models.pkl\")\n",
    "\n",
    "    return data\n",
    "data = prepare_for_different_models()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Baseline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function that performs cross-validation for several collaborative filtering algorithms using the Surprise library and returns the results in a pandas DataFrame. The function takes a Surprise dataset object as input and outputs two DataFrames, one with the results for each individual algorithm and another with the results for all algorithms.\n",
    "\n",
    "The algorithms used in this function are SVD, SVD++, SlopeOne, NMF, NormalPredictor, BaselineOnly, and CoClustering. For each algorithm, the function performs 5-fold cross-validation and computes the RMSE, MSE, MAE, and FCP metrics. The results are then stored in a DataFrame and saved to a file.\n",
    "\n",
    "Note that the function only runs the SVD algorithm by default. To run other algorithms, you need to uncomment the relevant lines in the for loop. Also, the function assumes that the saved_models_folder variable has been defined elsewhere in the code.\n",
    "\n",
    "Overall, this function provides a basic implementation of collaborative filtering algorithms using the Surprise library and can be used as a starting point for building more sophisticated recommendation systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import KFold\n",
    "'''\n",
    "Function that runs several collaborative filtering algorithms on an input dataset using cross-validation \n",
    "and computes several evaluation metrics. The function loops through a list of algorithms, \n",
    "runs cross-validation with each algorithm, computes the mean evaluation results across all folds, \n",
    "and appends the results to an overall list of results. It then saves the evaluation results \n",
    "of each algorithm in a Parquet file and saves the overall evaluation results of all algorithms \n",
    "in another Parquet file. The function returns the overall evaluation results.\n",
    "'''\n",
    "def baseline_all(data):\n",
    "    \n",
    "    # create an empty list to hold the benchmark results for all algorithms\n",
    "    benchmark = []\n",
    "\n",
    "    # instantiate the collaborative filtering algorithms we want to evaluate\n",
    "    svd = SVD()\n",
    "    svdp = SVDpp()\n",
    "    slpo = SlopeOne()\n",
    "    nm  = NMF()\n",
    "    nmlp = NormalPredictor()\n",
    "    baseonly = BaselineOnly()\n",
    "    coclus = CoClustering()\n",
    "\n",
    "    # loop through each algorithm and evaluate it using 5-fold cross-validation\n",
    "    for algorithm in [svd,svdp,slpo,nm,nmlp,baseonly,coclus]:\n",
    "\n",
    "        # create an empty list to hold the benchmark results for this algorithm\n",
    "        benchmark_inndividual = []\n",
    "        \n",
    "        # print a message to indicate which algorithm is being evaluated\n",
    "        print(algorithm,\"started\")\n",
    "\n",
    "        folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        # run 5-fold cross-validation and compute RMSE, MSE, MAE, and FCP metrics\n",
    "        results = cross_validate(algorithm, data, measures=['RMSE','MSE','MAE','FCP'], cv=folds, verbose=True)\n",
    "\n",
    "        # print a message to indicate that the algorithm has finished evaluating\n",
    "        print(algorithm,\"finished\")\n",
    "\n",
    "        # calculate the mean of each metric over the 5 folds and store the results in a DataFrame\n",
    "        tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "\n",
    "        # extract the name of the algorithm from the object and append it to the DataFrame\n",
    "        name = str(algorithm).split(' ')[0].split('.')[-1]\n",
    "        tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "\n",
    "        # add the results for this algorithm to the list of individual benchmark results\n",
    "        benchmark_inndividual.append(tmp)\n",
    "\n",
    "        # add the results for this algorithm to the list of global benchmark results\n",
    "        benchmark.append(tmp)\n",
    "\n",
    "        # convert the list of results for this algorithm to a DataFrame and save it to a file\n",
    "        dfscores_individual = pd.DataFrame(benchmark_inndividual).set_index('Algorithm').sort_values('test_rmse')\n",
    "        write(saved_models_folder + \"/\" + name + \"_results.parq\", dfscores_individual)\n",
    "    \n",
    "    # convert the list of benchmark results for all algorithms to a DataFrame and save it to a file\n",
    "    dfscores = pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')\n",
    "    write(saved_models_folder + \"/\" + \"Others_Models_results.parq\", dfscores)\n",
    "\n",
    "    # return the DataFrame with the benchmark results for all algorithms\n",
    "    return dfscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<surprise.prediction_algorithms.matrix_factorization.SVD object at 0x000001B9C9710760> started\n",
      "Evaluating RMSE, MSE, MAE, FCP of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.1336  1.1320  1.1339  1.1326  1.1328  1.1330  0.0007  \n",
      "MSE (testset)     1.2850  1.2814  1.2857  1.2827  1.2832  1.2836  0.0016  \n",
      "MAE (testset)     0.8447  0.8450  0.8448  0.8446  0.8446  0.8447  0.0001  \n",
      "FCP (testset)     0.7373  0.7360  0.7372  0.7370  0.7381  0.7371  0.0007  \n",
      "Fit time          132.24  123.20  125.49  134.83  130.43  129.24  4.29    \n",
      "Test time         57.05   44.47   41.61   37.90   44.47   45.10   6.44    \n",
      "<surprise.prediction_algorithms.matrix_factorization.SVD object at 0x000001B9C9710760> finished\n",
      "<surprise.prediction_algorithms.matrix_factorization.SVDpp object at 0x000001B9C97106D0> started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chrisitan\\AppData\\Local\\Temp\\ipykernel_4728\\3725587854.py:46: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MSE, MAE, FCP of algorithm SVDpp on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.1905  1.1902  1.1933  1.1947  1.1906  1.1919  0.0018  \n",
      "MSE (testset)     1.4173  1.4166  1.4239  1.4274  1.4176  1.4206  0.0043  \n",
      "MAE (testset)     0.8855  0.8863  0.8873  0.8894  0.8855  0.8868  0.0014  \n",
      "FCP (testset)     0.7319  0.7302  0.7301  0.7303  0.7314  0.7308  0.0007  \n",
      "Fit time          3544.44 3473.66 3421.99 3368.28 7073.26 4176.33 1449.64 \n",
      "Test time         847.75  880.16  797.56  877.29  883.70  857.29  32.50   \n",
      "<surprise.prediction_algorithms.matrix_factorization.SVDpp object at 0x000001B9C97106D0> finished\n",
      "<surprise.prediction_algorithms.slope_one.SlopeOne object at 0x000001B9C97107C0> started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chrisitan\\AppData\\Local\\Temp\\ipykernel_4728\\3725587854.py:46: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MSE, MAE, FCP of algorithm SlopeOne on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.1971  1.1951  1.1978  1.1960  1.1967  1.1965  0.0009  \n",
      "MSE (testset)     1.4330  1.4283  1.4346  1.4303  1.4322  1.4317  0.0022  \n",
      "MAE (testset)     0.9044  0.9031  0.9040  0.9037  0.9037  0.9038  0.0004  \n",
      "FCP (testset)     0.7118  0.7116  0.7120  0.7120  0.7118  0.7118  0.0002  \n",
      "Fit time          188.06  193.80  180.81  180.25  178.85  184.35  5.71    \n",
      "Test time         491.60  476.12  462.69  494.10  473.05  479.51  11.79   \n",
      "<surprise.prediction_algorithms.slope_one.SlopeOne object at 0x000001B9C97107C0> finished\n",
      "<surprise.prediction_algorithms.matrix_factorization.NMF object at 0x000001B9C9710640> started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chrisitan\\AppData\\Local\\Temp\\ipykernel_4728\\3725587854.py:46: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MSE, MAE, FCP of algorithm NMF on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    2.2375  2.2343  2.2268  2.2285  2.2243  2.2303  0.0049  \n",
      "MSE (testset)     5.0063  4.9921  4.9587  4.9661  4.9473  4.9741  0.0218  \n",
      "MAE (testset)     1.9860  1.9834  1.9756  1.9770  1.9727  1.9789  0.0050  \n",
      "FCP (testset)     0.6937  0.6924  0.6938  0.6932  0.6934  0.6933  0.0005  \n",
      "Fit time          224.69  225.17  228.94  230.22  227.73  227.35  2.13    \n",
      "Test time         58.46   46.38   56.34   56.19   55.78   54.63   4.23    \n",
      "<surprise.prediction_algorithms.matrix_factorization.NMF object at 0x000001B9C9710640> finished\n",
      "<surprise.prediction_algorithms.random_pred.NormalPredictor object at 0x000001B9C9710520> started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chrisitan\\AppData\\Local\\Temp\\ipykernel_4728\\3725587854.py:46: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MSE, MAE, FCP of algorithm NormalPredictor on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    2.1492  2.1462  2.1485  2.1482  2.1491  2.1482  0.0011  \n",
      "MSE (testset)     4.6192  4.6063  4.6160  4.6147  4.6185  4.6150  0.0046  \n",
      "MAE (testset)     1.7055  1.7029  1.7050  1.7042  1.7047  1.7045  0.0009  \n",
      "FCP (testset)     0.4977  0.4961  0.4978  0.4966  0.4981  0.4973  0.0008  \n",
      "Fit time          15.29   18.28   17.95   18.00   17.57   17.42   1.09    \n",
      "Test time         58.97   58.55   60.35   58.39   46.78   56.61   4.96    \n",
      "<surprise.prediction_algorithms.random_pred.NormalPredictor object at 0x000001B9C9710520> finished\n",
      "<surprise.prediction_algorithms.baseline_only.BaselineOnly object at 0x000001B9C9710730> started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chrisitan\\AppData\\Local\\Temp\\ipykernel_4728\\3725587854.py:46: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MSE, MAE, FCP of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.2064  1.2036  1.2071  1.2056  1.2061  1.2058  0.0012  \n",
      "MSE (testset)     1.4553  1.4486  1.4571  1.4534  1.4548  1.4539  0.0029  \n",
      "MAE (testset)     0.9173  0.9157  0.9172  0.9170  0.9169  0.9168  0.0006  \n",
      "FCP (testset)     0.7071  0.7070  0.7072  0.7070  0.7070  0.7071  0.0001  \n",
      "Fit time          28.92   31.63   32.12   31.98   32.96   31.52   1.37    \n",
      "Test time         50.63   50.88   49.84   40.42   37.89   45.93   5.60    \n",
      "<surprise.prediction_algorithms.baseline_only.BaselineOnly object at 0x000001B9C9710730> finished\n",
      "<surprise.prediction_algorithms.co_clustering.CoClustering object at 0x000001B9C9710880> started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chrisitan\\AppData\\Local\\Temp\\ipykernel_4728\\3725587854.py:46: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MSE, MAE, FCP of algorithm CoClustering on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.2144  1.2127  1.2099  1.2097  1.2083  1.2110  0.0022  \n",
      "MSE (testset)     1.4749  1.4707  1.4638  1.4634  1.4600  1.4666  0.0054  \n",
      "MAE (testset)     0.9180  0.9170  0.9138  0.9145  0.9131  0.9153  0.0019  \n",
      "FCP (testset)     0.7097  0.7104  0.7117  0.7122  0.7118  0.7112  0.0009  \n",
      "Fit time          355.75  338.44  373.09  370.90  355.04  358.64  12.56   \n",
      "Test time         41.79   68.12   56.65   60.35   41.96   53.78   10.40   \n",
      "<surprise.prediction_algorithms.co_clustering.CoClustering object at 0x000001B9C9710880> finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chrisitan\\AppData\\Local\\Temp\\ipykernel_4728\\3725587854.py:46: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>test_fcp</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>1.132956</td>\n",
       "      <td>1.283591</td>\n",
       "      <td>0.844734</td>\n",
       "      <td>0.737092</td>\n",
       "      <td>129.236504</td>\n",
       "      <td>45.101050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>1.191880</td>\n",
       "      <td>1.420580</td>\n",
       "      <td>0.886783</td>\n",
       "      <td>0.730786</td>\n",
       "      <td>4176.325600</td>\n",
       "      <td>857.291792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>1.196530</td>\n",
       "      <td>1.431685</td>\n",
       "      <td>0.903780</td>\n",
       "      <td>0.711841</td>\n",
       "      <td>184.353579</td>\n",
       "      <td>479.512936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>1.205758</td>\n",
       "      <td>1.453853</td>\n",
       "      <td>0.916848</td>\n",
       "      <td>0.707061</td>\n",
       "      <td>31.520678</td>\n",
       "      <td>45.932104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>1.211017</td>\n",
       "      <td>1.466567</td>\n",
       "      <td>0.915281</td>\n",
       "      <td>0.711172</td>\n",
       "      <td>358.642635</td>\n",
       "      <td>53.776164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>2.148245</td>\n",
       "      <td>4.614956</td>\n",
       "      <td>1.704465</td>\n",
       "      <td>0.497267</td>\n",
       "      <td>17.417936</td>\n",
       "      <td>56.607932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF</th>\n",
       "      <td>2.230265</td>\n",
       "      <td>4.974104</td>\n",
       "      <td>1.978937</td>\n",
       "      <td>0.693325</td>\n",
       "      <td>227.350313</td>\n",
       "      <td>54.632843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  test_mse  test_mae  test_fcp     fit_time  \\\n",
       "Algorithm                                                               \n",
       "SVD               1.132956  1.283591  0.844734  0.737092   129.236504   \n",
       "SVDpp             1.191880  1.420580  0.886783  0.730786  4176.325600   \n",
       "SlopeOne          1.196530  1.431685  0.903780  0.711841   184.353579   \n",
       "BaselineOnly      1.205758  1.453853  0.916848  0.707061    31.520678   \n",
       "CoClustering      1.211017  1.466567  0.915281  0.711172   358.642635   \n",
       "NormalPredictor   2.148245  4.614956  1.704465  0.497267    17.417936   \n",
       "NMF               2.230265  4.974104  1.978937  0.693325   227.350313   \n",
       "\n",
       "                  test_time  \n",
       "Algorithm                    \n",
       "SVD               45.101050  \n",
       "SVDpp            857.291792  \n",
       "SlopeOne         479.512936  \n",
       "BaselineOnly      45.932104  \n",
       "CoClustering      53.776164  \n",
       "NormalPredictor   56.607932  \n",
       "NMF               54.632843  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_all(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging results from Model Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>test_fcp</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>1.410689</td>\n",
       "      <td>1.990173</td>\n",
       "      <td>1.091799</td>\n",
       "      <td>0.549830</td>\n",
       "      <td>1.127742</td>\n",
       "      <td>0.291177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>1.413802</td>\n",
       "      <td>1.998886</td>\n",
       "      <td>1.098086</td>\n",
       "      <td>0.548991</td>\n",
       "      <td>1.091193</td>\n",
       "      <td>0.738526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>1.423057</td>\n",
       "      <td>2.025098</td>\n",
       "      <td>1.101095</td>\n",
       "      <td>0.555097</td>\n",
       "      <td>0.325870</td>\n",
       "      <td>0.144077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>1.582529</td>\n",
       "      <td>2.504417</td>\n",
       "      <td>1.207506</td>\n",
       "      <td>0.566946</td>\n",
       "      <td>4.946316</td>\n",
       "      <td>0.224878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>1.701391</td>\n",
       "      <td>2.894736</td>\n",
       "      <td>1.294262</td>\n",
       "      <td>0.458307</td>\n",
       "      <td>0.578457</td>\n",
       "      <td>0.310630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>2.139694</td>\n",
       "      <td>4.578297</td>\n",
       "      <td>1.696845</td>\n",
       "      <td>0.497400</td>\n",
       "      <td>0.116917</td>\n",
       "      <td>0.156717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF</th>\n",
       "      <td>2.499246</td>\n",
       "      <td>6.246258</td>\n",
       "      <td>2.119292</td>\n",
       "      <td>0.553087</td>\n",
       "      <td>3.484730</td>\n",
       "      <td>0.298785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  test_mse  test_mae  test_fcp  fit_time  test_time\n",
       "Algorithm                                                                    \n",
       "SVD               1.410689  1.990173  1.091799  0.549830  1.127742   0.291177\n",
       "SVDpp             1.413802  1.998886  1.098086  0.548991  1.091193   0.738526\n",
       "BaselineOnly      1.423057  2.025098  1.101095  0.555097  0.325870   0.144077\n",
       "CoClustering      1.582529  2.504417  1.207506  0.566946  4.946316   0.224878\n",
       "SlopeOne          1.701391  2.894736  1.294262  0.458307  0.578457   0.310630\n",
       "NormalPredictor   2.139694  4.578297  1.696845  0.497400  0.116917   0.156717\n",
       "NMF               2.499246  6.246258  2.119292  0.553087  3.484730   0.298785"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_others_results = pd.read_parquet(saved_models_folder + \"/\" + \"Others_Models_results.parq\", engine='fastparquet')\n",
    "df_others_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>test_fcp</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>1.643655</td>\n",
       "      <td>2.701632</td>\n",
       "      <td>1.275451</td>\n",
       "      <td>0.462612</td>\n",
       "      <td>35.4829</td>\n",
       "      <td>1.732444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           test_rmse  test_mse  test_mae  test_fcp  fit_time  test_time\n",
       "Algorithm                                                              \n",
       "KNNBasic    1.643655  2.701632  1.275451  0.462612   35.4829   1.732444"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_KNNBasic_results = pd.read_parquet(saved_models_folder + \"/\" + \"KNNBasic_results.parq\", engine='fastparquet')\n",
    "df_KNNBasic_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>test_fcp</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>1.498532</td>\n",
       "      <td>2.245621</td>\n",
       "      <td>1.156121</td>\n",
       "      <td>0.53585</td>\n",
       "      <td>32.409142</td>\n",
       "      <td>1.71859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             test_rmse  test_mse  test_mae  test_fcp   fit_time  test_time\n",
       "Algorithm                                                                 \n",
       "KNNBaseline   1.498532  2.245621  1.156121   0.53585  32.409142    1.71859"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_KNNBaseline_results = pd.read_parquet(saved_models_folder + \"/\" + \"KNNBaseline_results.parq\", engine='fastparquet')\n",
    "df_KNNBaseline_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>test_fcp</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>1.651630</td>\n",
       "      <td>2.727919</td>\n",
       "      <td>1.258240</td>\n",
       "      <td>0.466116</td>\n",
       "      <td>31.944902</td>\n",
       "      <td>1.796209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>1.666752</td>\n",
       "      <td>2.778087</td>\n",
       "      <td>1.267275</td>\n",
       "      <td>0.468789</td>\n",
       "      <td>36.883558</td>\n",
       "      <td>2.038430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               test_rmse  test_mse  test_mae  test_fcp   fit_time  test_time\n",
       "Algorithm                                                                   \n",
       "KNNWithMeans    1.651630  2.727919  1.258240  0.466116  31.944902   1.796209\n",
       "KNNWithZScore   1.666752  2.778087  1.267275  0.468789  36.883558   2.038430"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_knn_results = pd.read_parquet(saved_models_folder + \"/\" + \"KNN_Models_results.parq\", engine='fastparquet')\n",
    "df_knn_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_concat = pd.concat([df_others_results, df_KNNBasic_results,df_KNNBaseline_results,df_knn_results], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>test_fcp</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>1.410689</td>\n",
       "      <td>1.990173</td>\n",
       "      <td>1.091799</td>\n",
       "      <td>0.549830</td>\n",
       "      <td>1.127742</td>\n",
       "      <td>0.291177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>1.413802</td>\n",
       "      <td>1.998886</td>\n",
       "      <td>1.098086</td>\n",
       "      <td>0.548991</td>\n",
       "      <td>1.091193</td>\n",
       "      <td>0.738526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>1.423057</td>\n",
       "      <td>2.025098</td>\n",
       "      <td>1.101095</td>\n",
       "      <td>0.555097</td>\n",
       "      <td>0.325870</td>\n",
       "      <td>0.144077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>1.582529</td>\n",
       "      <td>2.504417</td>\n",
       "      <td>1.207506</td>\n",
       "      <td>0.566946</td>\n",
       "      <td>4.946316</td>\n",
       "      <td>0.224878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>1.701391</td>\n",
       "      <td>2.894736</td>\n",
       "      <td>1.294262</td>\n",
       "      <td>0.458307</td>\n",
       "      <td>0.578457</td>\n",
       "      <td>0.310630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>2.139694</td>\n",
       "      <td>4.578297</td>\n",
       "      <td>1.696845</td>\n",
       "      <td>0.497400</td>\n",
       "      <td>0.116917</td>\n",
       "      <td>0.156717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF</th>\n",
       "      <td>2.499246</td>\n",
       "      <td>6.246258</td>\n",
       "      <td>2.119292</td>\n",
       "      <td>0.553087</td>\n",
       "      <td>3.484730</td>\n",
       "      <td>0.298785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>1.643655</td>\n",
       "      <td>2.701632</td>\n",
       "      <td>1.275451</td>\n",
       "      <td>0.462612</td>\n",
       "      <td>35.482900</td>\n",
       "      <td>1.732444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>1.498532</td>\n",
       "      <td>2.245621</td>\n",
       "      <td>1.156121</td>\n",
       "      <td>0.535850</td>\n",
       "      <td>32.409142</td>\n",
       "      <td>1.718590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>1.651630</td>\n",
       "      <td>2.727919</td>\n",
       "      <td>1.258240</td>\n",
       "      <td>0.466116</td>\n",
       "      <td>31.944902</td>\n",
       "      <td>1.796209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>1.666752</td>\n",
       "      <td>2.778087</td>\n",
       "      <td>1.267275</td>\n",
       "      <td>0.468789</td>\n",
       "      <td>36.883558</td>\n",
       "      <td>2.038430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  test_mse  test_mae  test_fcp   fit_time  test_time\n",
       "Algorithm                                                                     \n",
       "SVD               1.410689  1.990173  1.091799  0.549830   1.127742   0.291177\n",
       "SVDpp             1.413802  1.998886  1.098086  0.548991   1.091193   0.738526\n",
       "BaselineOnly      1.423057  2.025098  1.101095  0.555097   0.325870   0.144077\n",
       "CoClustering      1.582529  2.504417  1.207506  0.566946   4.946316   0.224878\n",
       "SlopeOne          1.701391  2.894736  1.294262  0.458307   0.578457   0.310630\n",
       "NormalPredictor   2.139694  4.578297  1.696845  0.497400   0.116917   0.156717\n",
       "NMF               2.499246  6.246258  2.119292  0.553087   3.484730   0.298785\n",
       "KNNBasic          1.643655  2.701632  1.275451  0.462612  35.482900   1.732444\n",
       "KNNBaseline       1.498532  2.245621  1.156121  0.535850  32.409142   1.718590\n",
       "KNNWithMeans      1.651630  2.727919  1.258240  0.466116  31.944902   1.796209\n",
       "KNNWithZScore     1.666752  2.778087  1.267275  0.468789  36.883558   2.038430"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vertical_concat.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best result in test_rmse is test_rmse    1.410689\n",
      "Name: SVD, dtype: float64\n",
      "the best result in test_mse is test_rmse    1.410689\n",
      "Name: SVD, dtype: float64\n",
      "the best result in test_mae is test_rmse    1.410689\n",
      "Name: SVD, dtype: float64\n",
      "the best result in test_fcp is test_rmse    1.701391\n",
      "Name: SlopeOne, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "listatests =  [\"test_rmse\",\"test_mse\",\"test_mae\",\"test_fcp\"]\n",
    "for i in listatests:\n",
    "    print (\"the best result in\",i,\"is\",vertical_concat.iloc[vertical_concat[i].argmin(), 0:1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Selected models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have selected the 4 models with best results in the baseline. Now lets evaluate them doing GridSearchCV and training them to get the results.\n",
    "\n",
    "- svd = SVD()\n",
    "- svdp = SVDpp()\n",
    "- baseonly = BaselineOnly()\n",
    "- knnbase = KNNBaseline()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singular Value Decomposition (SVD) is a matrix factorization technique used in recommendation systems to reduce the dimensionality of a user-item matrix and identify latent factors that drive user-item interactions. In essence, SVD represents the original matrix as the product of three matrices: a user matrix, a singular value matrix, and an item matrix. The resulting factors can be used to make personalized recommendations by predicting a user's preference for an item based on their past behavior and the behavior of other similar users."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVDpp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD++ is an extension of Singular Value Decomposition (SVD) that takes into account implicit feedback in recommendation systems. In addition to the user-item matrix used in SVD, SVD++ also considers a matrix of implicit feedback such as user interactions with items, item attributes, and user preferences. This additional matrix helps capture the influence of user and item biases on the recommendation process, resulting in more accurate and personalized recommendations. SVD++ also includes a regularization term to avoid overfitting and improve generalization. Overall, SVD++ is a more advanced and sophisticated technique for recommendation systems than SVD."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaselineOnly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BaselineOnly is a simple but effective collaborative filtering algorithm used in recommendation systems. It predicts a user's rating for an item by taking into account the overall average rating of all items, the average rating of the user, and the average rating of the item. These three values are used as baseline estimates, and the difference between the actual rating and the baseline estimate is used as the prediction error. BaselineOnly then learns user and item biases that can improve the accuracy of the baseline estimates. The algorithm is simple and computationally efficient, making it a popular choice for recommendation systems with large datasets. However, it may not capture more complex relationships between users and items compared to more advanced techniques such as matrix factorization.BaselineOnly is a simple but effective collaborative filtering algorithm used in recommendation systems. It predicts a user's rating for an item by taking into account the overall average rating of all items, the average rating of the user, and the average rating of the item. These three values are used as baseline estimates, and the difference between the actual rating and the baseline estimate is used as the prediction error. BaselineOnly then learns user and item biases that can improve the accuracy of the baseline estimates. The algorithm is simple and computationally efficient, making it a popular choice for recommendation systems with large datasets. However, it may not capture more complex relationships between users and items compared to more advanced techniques such as matrix factorization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNNBaseline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNBaseline is a collaborative filtering algorithm used in recommendation systems that predicts a user's rating for an item based on the ratings of similar users or similar items. The algorithm is based on k-nearest neighbors, where k is the number of most similar users or items used to make the prediction. KNNBaseline uses a baseline estimate, which is similar to BaselineOnly, to normalize the ratings and improve the accuracy of the predictions. Additionally, KNNBaseline uses a similarity metric, such as cosine similarity or Pearson correlation, to measure the similarity between users or items. The algorithm can be used for both user-based and item-based recommendation systems and has been shown to produce accurate and effective recommendations for a wide range of datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and training the final selected SVD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chrisitan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os # allows access to OS-dependent functionalities\n",
    "import sys # to manipulate different parts of the Python runtime environment\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Add the path of the utils directory to sys.path\n",
    "utils_path = os.path.abspath(os.path.join(cwd, '..', 'utils'))\n",
    "sys.path.append(utils_path)\n",
    "\n",
    "# Utils libraries\n",
    "from cleaning import *\n",
    "from recommend import *\n",
    "from testing import *\n",
    "from training import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In roder to evaluate, select and train the desired model, we will use 3 different funcions from clening.py, testing.py and testing.py in utils folder:\n",
    "- supervised_prepare_training\n",
    "- find_best_svd\n",
    "- train_test_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(supervised_prepare_training.__doc__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is to:\n",
    "- Load 'anime.csv' file into a pandas DataFrame object called 'anime'\n",
    "- Load 'rating.csv.zip' file into a pandas DataFrame object called 'rating'\n",
    "- Create a new DataFrame 'anime_mapping' that is a copy of the 'anime' DataFrame and remove the 'episodes', 'members', and 'rating' columns\n",
    "- Filter out all ratings less than or equal to 0 and reset the index of the DataFrame\n",
    "- Drop the 'index' column and update the DataFrame in-place\n",
    "- Get the shape of the DataFrame 'ratingdf'\n",
    "- Set the size to 100,000 and sample from the 'ratingdf' DataFrame based on the proportion of ratings for each score\n",
    "- This will make sure that the sampled data has roughly the same proportion of ratings for each score as the original data\n",
    "- Create a new 'Reader' object with the rating scale set to a range between 1 and 10\n",
    "- Load the sampled data into a 'Dataset' object using the 'load_from_df' method and the 'reader' object\n",
    "- Saving the table to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x2cafb97a640>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "supervised_prepare_training() #utils.cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(find_best_svd.__doc__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps of find_best_svd:\n",
    "- Define parameter grid for grid search\n",
    "- Create GridSearchCV object with SVD algorithm\n",
    "- Fit GridSearchCV object to data\n",
    "- Print best RMSE and MAE scores, as well as corresponding parameters\n",
    "- Save model with best parameters\n",
    "- Save best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score: 1.3805614676765472\n",
      "Best MAE score: 1.0649921646188643\n",
      "Best parameters for RMSE: {'n_factors': 50, 'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.1}\n",
      "Best parameters for MAE: {'n_factors': 50, 'n_epochs': 40, 'lr_all': 0.01, 'reg_all': 0.1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.model_selection.search.GridSearchCV at 0x2cafb917ac0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_svd() #utils.testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_test_svd.__doc__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps of train_test_svd:\n",
    "- Loads the best hyperparameters for the SVD algorithm that were obtained from grid search\n",
    "- Loads the dataset from a pickle file using joblib\n",
    "- Splits the data into training and testing sets with a 80:20 ratio\n",
    "- Creates an instance of the SVD algorithm with the best hyperparameters obtained from grid search\n",
    "- Trains the SVD algorithm on the training set using the fit() method\n",
    "- Generates predictions for the test set using the trained model\n",
    "- Calculates the RMSE and MAE for the predictions\n",
    "- Saves the trained model as a pickle file using joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3757\n",
      "MAE:  1.0561\n",
      "RMSE: 1.375737289908081\n",
      "MAE: 1.056142242807008\n"
     ]
    }
   ],
   "source": [
    "train_test_svd() #utils.training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting recommendations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the recommendations we will use the next functions from recommend.py in utils folder:\n",
    "- sort_it\n",
    "- create_dict_su\n",
    "- filtering_and\n",
    "- filtering_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sort_it.__doc__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps of sort_it:\n",
    "- Load the pre-trained SVD model   \n",
    "- Load the anime dataframe  \n",
    "- Apply the SVD model to estimate the score for each anime\n",
    "- Sort the dataframe by the estimated score in descending order and drop the anime_id column\n",
    "- Create a blank index for the dataframe\n",
    "- Set the blank index to the dataframe\n",
    "- Return the sorted dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_dict_su.__doc__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps of create_dict_su:\n",
    "- get the final dataframe and the parameters for filtering and number of recommendations to show\n",
    "- check which method was used to filter the recommendations, 'or' or 'and'\n",
    "\t- filter the dataframe using the OR logic and the given genres and types\n",
    "\t- filter the dataframe using the AND logic and the given genres and types\n",
    "\t- raise an error if an invalid filter type was given     \n",
    "- select the top n recommendations from the filtered dataframe\n",
    "- if the filtered dataframe is empty, print a message\n",
    "\t- convert the filtered dataframe to a dictionary\n",
    "\t- return the dictionary of recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    This function takes a DataFrame df, a list of genres, and a list of types as input arguments. \n",
      "    The function first creates a boolean mask genre_mask by applying a lambda function to \n",
      "    the 'genre' column of the DataFrame. The lambda function checks if the value is a \n",
      "    string using isinstance(x, str) and if all genres in the genres list are present \n",
      "    in the string, which is split by comma and space using x.split(', '). \n",
      "    The all() function returns True if all genres in the genres list are present \n",
      "    in the string. The resulting genre_mask will be True for rows where the genre \n",
      "    column contains all of the genres in the genres list.\n",
      "\n",
      "    Then the function creates another boolean mask type_mask by using the isin() \n",
      "    method to check if each value in the 'type' column of the DataFrame is in the types list.\n",
      "\n",
      "    Finally, the function applies both masks to the DataFrame df using the & operator \n",
      "    to create a new DataFrame filtered_df that includes only rows where both m\n",
      "    asks are True. The function returns the filtered DataFrame.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(filtering_and.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps of filtering_and:\n",
    "- This function takes a DataFrame `df`, a list of `genres`, and a list of `types` as input arguments.\n",
    "- Create a boolean mask that filters rows where the genre column contains all of the genres in the `genres` list.\n",
    "- Create a boolean mask that filters rows where the type column is in the `types` list.\n",
    "- Apply both masks to the DataFrame `df` and create a new DataFrame `filtered_df` that includes only rows where both masks are True.\n",
    "- Return the filtered DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The code defines a function \"filtering_or\" that filters a pandas dataframe based on user-defined \n",
      "    genres and types using an \"OR\" method. The function allows the user to select one or all possible \n",
      "    genres and types and returns a filtered dataframe with the selected genres and types. \n",
      "    The function also splits the genre and type columns and explodes them to account for multiple entries.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(filtering_or.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps of filtering_or:\n",
    "- Make a copy of the input DataFrame\n",
    "- Split the genre column into a list of genres\n",
    "- Explode the genre column to create a new row for each genre in the list\n",
    "- If genres are specified and 'ALL' is not one of them, filter the DataFrame to keep only rows where the genre is in the specified list  \n",
    "- If types are specified and 'ALL' is not one of them, filter the DataFrame to keep only rows where the type is in the specified list\n",
    "- If both genres and types are specified\n",
    "- If 'ALL' is in the genres list, set genres to be all the unique genres in the filtered DataFrame\n",
    "- If 'ALL' is in the types list, set types to be all the unique types in the filtered DataFrame\n",
    "- Filter the DataFrame to keep only rows where the genre is in the genres list AND the type is in the types list\n",
    "- Return the filtered DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Fullmetal Alchemist: Brotherhood',\n",
       "  'english_title': 'Fullmetal Alchemist: Brotherhood',\n",
       "  'japanses_title': ' FULLMETAL ALCHEMIST',\n",
       "  'genre': 'Shounen',\n",
       "  'type': 'TV',\n",
       "  'source': 'Manga',\n",
       "  'duration': '24 min per ep',\n",
       "  'episodes': '64',\n",
       "  'rating': 'R - 17+ (violence & profanity)',\n",
       "  'score': 9.11,\n",
       "  'rank': 1.0,\n",
       "  'members': 793665,\n",
       "  'synopsis': 'After a horrific alchemy experiment goes wrong in the Elric household, brothers Edward and Alphonse are left in a catastrophic new reality. Ignoring the alchemical principle banning human transmutation, the boys attempted to bring their recently deceased mother back to life. Instead, they suffered brutal personal loss: Alphonse\\'s body disintegrated while Edward lost a leg and then sacrificed an arm to keep Alphonse\\'s soul in the physical realm by binding it to a hulking suit of armor.\\r\\n\\r\\nThe brothers are rescued by their neighbor Pinako Rockbell and her granddaughter Winry. Known as a bio-mechanical engineering prodigy, Winry creates prosthetic limbs for Edward by utilizing \"automail,\" a tough, versatile metal used in robots and combat armor. After years of training, the Elric brothers set off on a quest to restore their bodies by locating the Philosopher\\'s Stonea powerful gem that allows an alchemist to defy the traditional laws of Equivalent Exchange.\\r\\n\\r\\nAs Edward becomes an infamous alchemist and gains the nickname \"Fullmetal,\" the boys\\' journey embroils them in a growing conspiracy that threatens the fate of the world.\\r\\n\\r\\n[Written by MAL Rewrite]',\n",
       "  'cover': 'https://cdn.myanimelist.net/images/anime/1208/94745l.jpg',\n",
       "  'Estimate_Score': 9.240005320221256},\n",
       " {'name': 'Gintama',\n",
       "  'english_title': 'Gintama',\n",
       "  'japanses_title': '',\n",
       "  'genre': 'Shounen',\n",
       "  'type': 'TV',\n",
       "  'source': 'Manga',\n",
       "  'duration': '24 min per ep',\n",
       "  'episodes': '51',\n",
       "  'rating': 'PG-13 - Teens 13 or older',\n",
       "  'score': 9.07,\n",
       "  'rank': 4.0,\n",
       "  'members': 114262,\n",
       "  'synopsis': \"Gintoki, Shinpachi, and Kagura return as the fun-loving but broke members of the Yorozuya team! Living in an alternate-reality Edo, where swords are prohibited and alien overlords have conquered Japan, they try to thrive on doing whatever work they can get their hands on. However, Shinpachi and Kagura still haven't been paid... Does Gin-chan really spend all that cash playing pachinko?\\r\\n\\r\\nMeanwhile, when Gintoki drunkenly staggers home one night, an alien spaceship crashes nearby. A fatally injured crew member emerges from the ship and gives Gintoki a strange, clock-shaped device, warning him that it is incredibly powerful and must be safeguarded. Mistaking it for his alarm clock, Gintoki proceeds to smash the device the next morning and suddenly discovers that the world outside his apartment has come to a standstill. With Kagura and Shinpachi at his side, he sets off to get the device fixed; though, as usual, nothing is ever that simple for the Yorozuya team.\\r\\n\\r\\nFilled with tongue-in-cheek humor and moments of heartfelt emotion, Gintama's fourth season finds Gintoki and his friends facing both their most hilarious misadventures and most dangerous crises yet.\\r\\n\\r\\n[Written by MAL Rewrite]\",\n",
       "  'cover': 'https://cdn.myanimelist.net/images/anime/3/72078l.jpg',\n",
       "  'Estimate_Score': 9.197089662352965},\n",
       " {'name': 'Haikyuu!!: Karasuno Koukou VS Shiratorizawa Gakuen Koukou',\n",
       "  'english_title': 'Haikyuu!! Karasuno Koukou vs. Shiratorizawa Gakuen Koukou',\n",
       "  'japanses_title': '!!  VS ',\n",
       "  'genre': 'Shounen',\n",
       "  'type': 'TV',\n",
       "  'source': 'Manga',\n",
       "  'duration': '24 min per ep',\n",
       "  'episodes': '10',\n",
       "  'rating': 'PG-13 - Teens 13 or older',\n",
       "  'score': 8.78,\n",
       "  'rank': 35.0,\n",
       "  'members': 93351,\n",
       "  'synopsis': 'After the victory against Aoba Jousai High, Karasuno High School, once called a fallen powerhouse, a crow that cant fly, has finally reached the climax of the heated Spring tournament. Now, to advance to nationals, the Karasuno team has to defeat the powerhouse Shiratorizawa Academy. Karasunos greatest hurdle is their adversarys ace, Wakatoshi Ushijima, the number one player in the Miyagi Prefecture, and one of the countrys top three aces.\\r\\n\\r\\nOnly the strongest team will make it to the national tournament. Since this match is the third-year players last chance to qualify for nationals, Karasuno has to use everything they learned during the training camp and prior matches to attain victory. Filled with restlessness and excitement, both teams are determined to come out on top in the third season of Haikyuu!!.\\r\\n\\r\\n[Written by MAL Rewrite]',\n",
       "  'cover': 'https://cdn.myanimelist.net/images/anime/7/81992l.jpg',\n",
       "  'Estimate_Score': 9.191643739956707},\n",
       " {'name': 'Hunter x Hunter (2011)',\n",
       "  'english_title': 'Hunter x Hunter (2011)',\n",
       "  'japanses_title': 'HUNTERHUNTER',\n",
       "  'genre': 'Shounen',\n",
       "  'type': 'TV',\n",
       "  'source': 'Manga',\n",
       "  'duration': '23 min per ep',\n",
       "  'episodes': '148',\n",
       "  'rating': 'PG-13 - Teens 13 or older',\n",
       "  'score': 9.04,\n",
       "  'rank': 9.0,\n",
       "  'members': 425855,\n",
       "  'synopsis': \"Hunters devote themselves to accomplishing hazardous tasks, all from traversing the world's uncharted territories to locating rare items and monsters. Before becoming a Hunter, one must pass the Hunter Examinationa high-risk selection process in which most applicants end up handicapped or worse, deceased.\\r\\n\\r\\nAmbitious participants who challenge the notorious exam carry their own reason. What drives 12-year-old Gon Freecss is finding Ging, his father and a Hunter himself. Believing that he will meet his father by becoming a Hunter, Gon takes the first step to walk the same path.\\r\\n\\r\\nDuring the Hunter Examination, Gon befriends the medical student Leorio Paladiknight, the vindictive Kurapika, and ex-assassin Killua Zoldyck. While their motives vastly differ from each other, they band together for a common goal and begin to venture into a perilous world.\\r\\n\\r\\n[Written by MAL Rewrite]\",\n",
       "  'cover': 'https://cdn.myanimelist.net/images/anime/1337/99013l.jpg',\n",
       "  'Estimate_Score': 9.166091462407456},\n",
       " {'name': 'Gintama&#039;: Enchousen',\n",
       "  'english_title': \"Gintama': Enchousen\",\n",
       "  'japanses_title': \"' \",\n",
       "  'genre': 'Shounen',\n",
       "  'type': 'TV',\n",
       "  'source': 'Manga',\n",
       "  'duration': '24 min per ep',\n",
       "  'episodes': '13',\n",
       "  'rating': 'PG-13 - Teens 13 or older',\n",
       "  'score': 9.03,\n",
       "  'rank': 10.0,\n",
       "  'members': 81109,\n",
       "  'synopsis': \"While Gintoki Sakata was away, the Yorozuya found themselves a new leader: Kintoki, Gintoki's golden-haired doppelganger. In order to regain his former position, Gintoki will need the help of those around him, a troubling feat when no one can remember him! Between Kintoki and Gintoki, who will claim the throne as the main character?\\r\\n\\r\\nIn addition, Yorozuya make a trip back down to red-light district of Yoshiwara to aid an elderly courtesan in her search for her long-lost lover. Although the district is no longer in chains beneath the earth's surface, the trio soon learn of the tragic backstories of Yoshiwara's inhabitants that still haunt them. With flashback after flashback, this quest has Yorozuya witnessing everlasting love and protecting it as best they can with their hearts and souls.\\r\\n\\r\\n[Written by MAL Rewrite]\",\n",
       "  'cover': 'https://cdn.myanimelist.net/images/anime/1452/123686l.jpg',\n",
       "  'Estimate_Score': 9.16261420396817},\n",
       " {'name': 'Gintama',\n",
       "  'english_title': 'Gintama',\n",
       "  'japanses_title': '',\n",
       "  'genre': 'Shounen',\n",
       "  'type': 'TV',\n",
       "  'source': 'Manga',\n",
       "  'duration': '24 min per ep',\n",
       "  'episodes': '201',\n",
       "  'rating': 'PG-13 - Teens 13 or older',\n",
       "  'score': 8.94,\n",
       "  'rank': 17.0,\n",
       "  'members': 336376,\n",
       "  'synopsis': 'Edo is a city that was home to the vigor and ambition of samurai across the country. However, following feudal Japan\\'s surrender to powerful aliens known as the \"Amanto,\" those aspirations now seem unachievable. With the once-influential shogunate rebuilt as a puppet government, a new law is passed that promptly prohibits all swords in public. \\r\\n\\r\\nEnter Gintoki Sakata, an eccentric silver-haired man who always carries around a wooden sword and maintains his stature as a samurai despite the ban. As the founder of Yorozuya, a small business for odd jobs, Gintoki often embarks on endeavors to help other peoplethough usually in rather strange and unforeseen ways. \\r\\n\\r\\nAssisted by Shinpachi Shimura, a boy with glasses supposedly learning the way of the samurai; Kagura, a tomboyish girl with superhuman strength and an endless appetite; and Sadaharu, their giant pet dog who loves biting on people\\'s heads, the Yorozuya encounter anything from alien royalty to scuffles with local gangs in the ever-changing world of Edo.\\r\\n\\r\\n[Written by MAL Rewrite]',\n",
       "  'cover': 'https://cdn.myanimelist.net/images/anime/10/73274l.jpg',\n",
       "  'Estimate_Score': 9.150980537216345},\n",
       " {'name': 'Gintama&#039;',\n",
       "  'english_title': \"Gintama'\",\n",
       "  'japanses_title': \"'\",\n",
       "  'genre': 'Shounen',\n",
       "  'type': 'TV',\n",
       "  'source': 'Manga',\n",
       "  'duration': '24 min per ep',\n",
       "  'episodes': '51',\n",
       "  'rating': 'PG-13 - Teens 13 or older',\n",
       "  'score': 9.04,\n",
       "  'rank': 8.0,\n",
       "  'members': 151266,\n",
       "  'synopsis': \"After a one-year hiatus, Shinpachi Shimura returns to Edo, only to stumble upon a shocking surprise: Gintoki and Kagura, his fellow Yorozuya members, have become completely different characters! Fleeing from the Yorozuya headquarters in confusion, Shinpachi finds that all the denizens of Edo have undergone impossibly extreme changes, in both appearance and personality. Most unbelievably, his sister Otae has married the Shinsengumi chief and shameless stalker Isao Kondou and is pregnant with their first child.\\r\\n\\r\\nBewildered, Shinpachi agrees to join the Shinsengumi at Otae and Kondou's request and finds even more startling transformations afoot both in and out of the ranks of the the organization. However, discovering that Vice Chief Toushirou Hijikata has remained unchanged, Shinpachi and his unlikely Shinsengumi ally set out to return the city of Edo to how they remember it.\\r\\n\\r\\nWith even more dirty jokes, tongue-in-cheek parodies, and shameless references, Gintama' follows the Yorozuya team through more of their misadventures in the vibrant, alien-filled world of Edo.\\r\\n\\r\\n[Written by MAL Rewrite]\",\n",
       "  'cover': 'https://cdn.myanimelist.net/images/anime/4/50361l.jpg',\n",
       "  'Estimate_Score': 9.096140703215436},\n",
       " {'name': 'Aria The Origination',\n",
       "  'english_title': 'Aria the Origination',\n",
       "  'japanses_title': 'ARIA The ORIGINATION',\n",
       "  'genre': 'Shounen',\n",
       "  'type': 'TV',\n",
       "  'source': 'Manga',\n",
       "  'duration': '24 min per ep',\n",
       "  'episodes': '13',\n",
       "  'rating': 'G - All Ages',\n",
       "  'score': 8.49,\n",
       "  'rank': 130.0,\n",
       "  'members': 56162,\n",
       "  'synopsis': 'In the 24th century on the planet Aqua, three girlsAkari Mizunashi, Alice Carroll, and Aika S. Granzchestacontinue to work hard toward achieving their goal of becoming Prima Undines: professional tour guide gondoliers. Luckily, the girls have the guidance of the three best Prima Undines in Neo-VeneziaAlicia Florence, Athena Glory, and Akira E. Ferrariwho are known as the \"Water Fairies\" in honor of their skill. With their help, the young apprentices train hard and work to overcome any situations that they find themselves in.\\r\\n\\r\\nAria The Origination follows the hardships and daily lives of these three young girls, who are doing their best to improve as tour gondoliers in Neo-Venezia, a terraformed replica of Venice.\\r\\n\\r\\n[Written by MAL Rewrite]',\n",
       "  'cover': 'https://cdn.myanimelist.net/images/anime/1394/129606l.jpg',\n",
       "  'Estimate_Score': 8.91693800648121},\n",
       " {'name': 'Hajime no Ippo',\n",
       "  'english_title': 'Hajime no Ippo',\n",
       "  'japanses_title': ' THE FIGHTING!',\n",
       "  'genre': 'Shounen',\n",
       "  'type': 'TV',\n",
       "  'source': 'Manga',\n",
       "  'duration': '23 min per ep',\n",
       "  'episodes': '75',\n",
       "  'rating': 'PG-13 - Teens 13 or older',\n",
       "  'score': 8.75,\n",
       "  'rank': 41.0,\n",
       "  'members': 157670,\n",
       "  'synopsis': \"In his father's absence, teenager Ippo Makunouchi works hard to help his mother run her fishing boat rental business. Ippo's timid nature, his lack of sleep, and the sea smell make him an easy target for relentless bullies who leave him bruised and beaten on a daily basis. Mamoru Takamura, an up-and-coming boxer, rescues Ippo from a violent after-school incident and takes him back to the Kamogawa Boxing Gym for recovery. Takamura and his fellow boxers, Masaru Aoki and Tatsuya Kimura, are stunned by Ippo's powerful punchesa result of strong muscles developed through years serving his physically taxing family business. \\r\\n\\r\\nFollowing brief training under Takamura, Ippo impresses the other boxers in a practice match against prodigy Ichirou Miyata. He gains a rival in Miyata and a coach in Genji Kamogawa, the gym owner and a former boxer himself. As Ippo takes the first steps in his official boxing career, he faces off against a series of challenging opponents, each more powerful than the last. Victory, loss, and a cycle of dedicated training await Ippo on his journey to achieve greatness. With his tough body and unstoppable fighting spirit, the kind young man seeks to take on the world.\\r\\n\\r\\n[Written by MAL Rewrite]\",\n",
       "  'cover': 'https://cdn.myanimelist.net/images/anime/4/86334l.jpg',\n",
       "  'Estimate_Score': 8.91608397569709},\n",
       " {'name': 'Shigatsu wa Kimi no Uso',\n",
       "  'english_title': 'Shigatsu wa Kimi no Uso',\n",
       "  'japanses_title': '',\n",
       "  'genre': 'Shounen',\n",
       "  'type': 'TV',\n",
       "  'source': 'Manga',\n",
       "  'duration': '22 min per ep',\n",
       "  'episodes': '22',\n",
       "  'rating': 'PG-13 - Teens 13 or older',\n",
       "  'score': 8.65,\n",
       "  'rank': 68.0,\n",
       "  'members': 416397,\n",
       "  'synopsis': 'Kousei Arima is a child prodigy known as the \"Human Metronome\" for playing the piano with precision and perfection. Guided by a strict mother and rigorous training, Kousei dominates every competition he enters, earning the admiration of his musical peers and praise from audiences. When his mother suddenly passes away, the subsequent trauma makes him unable to hear the sound of a piano, and he never takes the stage thereafter.\\r\\n\\r\\nNowadays, Kousei lives a quiet and unassuming life as a junior high school student alongside his friends Tsubaki Sawabe and Ryouta Watari. While struggling to get over his mother\\'s death, he continues to cling to music. His monochrome life turns upside down the day he encounters the eccentric violinist Kaori Miyazono, who thrusts him back into the spotlight as her accompanist. Through a little lie, these two young musicians grow closer together as Kaori tries to fill Kousei\\'s world with color.\\r\\n\\r\\n[Written by MAL Rewrite]',\n",
       "  'cover': 'https://cdn.myanimelist.net/images/anime/3/67177l.jpg',\n",
       "  'Estimate_Score': 8.86332360872485}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can get the recommendation as a dictionary\n",
    "# We input the user ID for we want the recommendations\n",
    "# Then the genre we want (or write \"All\" if we shoose \"or\" filter)\n",
    "# Then the type we want (or write \"All\" if we shoose \"or\" filter)\n",
    "# We must select a type or filtering, \"or\"/\"and\" \n",
    "# Then the number of suggestions we have(we might get less if there not so many o none if there is no matches)\n",
    "\n",
    "create_dict_su(sort_it(25000),[\"Shounen\"],[\"TV\"],\"or\",10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b81dc10ae865b1cfc2801720682109336e501398cc38da3c954913355cae8fad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
